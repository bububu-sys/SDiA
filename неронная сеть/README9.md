**Задание 4: Image Segmentation (Сегментация изображений)**
----------------------------------------------------------------------------
Задача: реализовать простую U-Net архитектуру для сегментации изображений.
Требования:
- Encoder-Decoder архитектура
- Skip connections между encoder и decoder
- Dice loss функция
Код-заготовка (C++):
class UNet {
private:
 // TODO: Определить слои encoder и decoder

public:
 
 UNet() {
 
 // TODO: Инициализировать архитектуру U-Net
 
 }

 
 Matrix encode(const Matrix& input) {
 
 // TODO: Encoder path с downsampling
 
 }

 
 Matrix decode(const Matrix& encoded,
 
 const std::vector<Matrix>& skip_connections) {
 
 // TODO: Decoder path с upsampling
 
 }

 
 Matrix forward(const Matrix& input) {
 
 // TODO: Полное прямое распространение с skip connections
 
 }

 
 double dice_loss(const Matrix& pred, const Matrix& target) {
 
 // TODO: Реализовать Dice loss
 
 // Dice = 2 * |X ∩ Y| / (|X| + |Y|)
 
 }

};
___________________________________________________________________________________
// Что нужно дополнить:

// 1. Слои свёртки и пулинга

// 2. Транспонированные свёртки для upsampling

// 3. Skip connections

// 4. Dice loss и его градиент
_________________________________________________________________________________
**Анализ структуры нейронной сети по блокам**
---------------------------------------------------------------
**1. Входной блок**

 - Назначение: Приём и предобработка данных (нормализация, аугментация).

 - Компоненты: Слой ввода, нормализация, аугментация.

**2. Свёрточные блоки (Encoder)**

 - Назначение: Извлечение признаков с понижением размерности.

 - Компоненты:

   * Conv2D + BatchNorm + ReLU

   * MaxPooling для downsampling

   * Skip connections для сохранения информации

**3. Блоки декодера (Decoder)**

 - Назначение: Восстановление пространственной информации.

 - Компоненты:

   * Conv2DTranspose для upsampling

   * Конкатенация с skip connections

   * Conv2D + BatchNorm + ReLU

**4. Выходной блок**

- Назначение: Генерация конечного предсказания.

- Компоненты:

- Финальная свёртка (1x1)

- Активация (sigmoid/softmax)

- Reshape в целевую размерность

**5. Функции потерь и оптимизации**

- Loss functions: Dice loss, BCE, MSE

- Optimizers: Adam, SGD с momentum

- Регуляризация: Dropout, L2, batch normalization

**6. Особенности U-Net**

- Симметричность: Encoder-Decoder с одинаковой глубиной

- Skip connections: Конкатенация feature maps энкодера и декодера

- Локальность и контекст: Мелкие детали + семантическая информация
_________________________________________________________________________________
**Ответы на контрольные вопросы (страница 72)**
---------------------------------------------------------------------
**Автоматы и регулярные выражения**

- DFA vs NFA: DFA детерминированный — для каждого состояния и символа ровно один переход. NFA может иметь несколько переходов, включая ε-переходы.

- Thompson's Construction: Рекурсивно строит NFA из регулярных выражений через операции конкатенации, объединения и замыкания.

- Теорема Ардена: Позволяет решать уравнения вида 
X=A⋅X∪B для преобразования DFA в регулярное выражение.

- Преобразование NFA в DFA: Через построение подмножеств — состояния DFA = множества состояний NFA.

**Алгоритмы во внешней памяти**

- External Merge Sort: Сортирует данные, не помещающиеся в RAM, через разбиение на блоки, сортировку в памяти и k-стороннее слияние.

- I/O Complexity: Дисковая память медленнее, поэтому главный критерий — количество операций чтения/записи.

- Размер блока: Выбирается кратно размеру страницы диска для минимизации seek time.

**Вычислительная геометрия**

- Graham Scan: Находит выпуклую оболочку через сортировку по полярному углу и стек. Сложность 
O(n log n).

- Диаграммы Вороного: Разбиение плоскости на области ближайших точек. Применение: геоинформатика, робототехника.

- Триангуляция Делоне: Максимизирует минимальный угол, избегает узких треугольников.

**Нечёткие множества**

- Type-I vs Type-II: Type-I — одна функция принадлежности. Type-II — функция принадлежности сама нечёткая (интервал).

- Fuzzy C-Means: Точки могут принадлежать нескольким кластерам с разной степенью (в отличие от K-Means).

- Степень принадлежности: Функция A (x)∈ [0,1].

**Теория игр**

- Minimax: Игрок MAX максимизирует минимальный выигрыш. Применение: игры с нулевой суммой.

- Alpha-Beta Pruning: Отсекает ветви, не влияющие на результат. Снижает сложность.

**Машинное обучение**

- KNN vs K-Means: KNN — классификация по соседям, K-Means — кластеризация без учителя.

- DBSCAN: Работает на плотности, находит кластеры произвольной формы.

- Affinity Propagation: Автоматически выбирает exemplars через обмен сообщениями.

- Spectral Clustering: Использует собственные векторы матрицы сходства для лучшего разделения.

**Нейронные сети**

- Backpropagation: Цепное правило для вычисления градиентов от выхода ко входу.

- SGD with Momentum: Добавляет инерцию для ускорения сходимости и сглаживания.

- Pruning: Удаление малозначимых весов. Optimal Brain Damage использует гессиан.

- Генетические алгоритмы: Эволюционная оптимизация весов через селекцию, кроссовер, мутацию.

- Rprop: Адаптивный размер шага для каждого веса.

- Batch vs SGD vs Mini-batch: Batch — весь датасет, SGD — один пример, Mini-batch — подмножество.

- Переобучение: Регуляризация, dropout, аугментация, ранняя остановка.

- Vanishing gradient: Решение: ReLU, residual connections, batch normalization.

- Dropout: Случайное отключение нейронов для предотвращения ко-адаптации.

- ReLU vs Sigmoid: ReLU не насыщается, быстрее, борется с vanishing gradient.

- Выбор архитектуры: Зависит от задачи: CNN — изображения, RNN — последовательности, Transformer — текст.
________________________________________________________________________________________________
**Вывод из терминала после обучения**
---------------------------------------------------------------------------
<img width="1196" height="927" alt="Снимок экрана 2025-12-14 224513" src="https://github.com/user-attachments/assets/a4a77272-eb77-4a69-a6f0-2c54b8b51fcf" />

<img width="1207" height="774" alt="Снимок экрана 2025-12-14 224521" src="https://github.com/user-attachments/assets/fdeddff0-3a09-4d1c-8cd2-3734d10c93ec" />

<img width="1172" height="774" alt="Снимок экрана 2025-12-14 224535" src="https://github.com/user-attachments/assets/f66975cd-74f5-411f-8145-27583d9517a8" />

